Practical3: Multiple Linear Regression
Code:
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Load and clean data
data = pd.read_csv('demo.csv').replace([np.inf, -np.inf], np.nan).dropna()

# Define features and target
X = data[['Width', 'Kilometer']]
y = data['Height']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)

# Train model
model = LinearRegression().fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Print results
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {dict(zip(X.columns, model.coef_))}")
print(f"R² Score: {model.score(X_test, y_test)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}")

Practical4: K-Neighbour
Winedate:
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_wine

winedata= load_wine()
x=winedata.data
y=winedata.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

knn=KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train, y_train)
acc=knn.score(x_test, y_test)
print(acc)
y_pred=knn.predict(x_test)
print(y_pred)

cm=confusion_matrix(y_test, y_pred)
print(cm)

plt.figure(figsize=(8,6))
sns.heatmap(cm,annot=True,fmt='g',cmap='Blues',xticklabels=winedata.target_names,yticklabels=winedata.target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()


Kneighbour(Wine Dataset With Scaling):
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_wine

X, y = load_wine(return_X_y=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)

print(X_test[:5])//Use this for printing few test data
print("Accuracy:", knn.score(X_test, y_test))








Kneighbour(Wine Dataset With Scaling):But only on two features:
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
import pandas as pd

# Load Wine dataset
data = load_wine()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target)
X = X[["proline", "hue"]]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

knn = KNeighborsClassifier(n_neighbors=9)
knn.fit(X_train, y_train)

print("Model Accuracy:", knn.score(X_test, y_test))


Prac5: Decision Tree Clasifier
Code:
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder
from sklearn.metrics import accuracy_score, confusion_matrix

col_names = ["outlook", "temp", "humidity", "wind", "play"]
data = pd.read_csv("PlayTennis.csv", header=None, names=col_names)

x = OrdinalEncoder().fit_transform(data.iloc[:, :-1])
y = LabelEncoder().fit_transform(data.iloc[:, -1])

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

model = DecisionTreeClassifier()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
print("Predictions:", y_pred)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

print("\nDecision Tree Rules:\n", export_text(model, feature_names=col_names[:-1]))

plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=col_names[:-1], class_names=[str(cls) for cls in set(y)], max_depth=3)
plt.show()



DT&Bayes on Diabetes.csv:
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score

col_names = ["Pregnancies","Glucose","BloodPressure","SkinThickness","Insulin","BMI",
             "DiabetesPedigreeFunction","Age","Outcome"]
pima = pd.read_csv("diabetes.csv", header=None, names=col_names)

x, y = pima.iloc[:, :-1], pima.iloc[:, -1]
x, y = OrdinalEncoder().fit_transform(x), LabelEncoder().fit_transform(y)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

dt_model = DecisionTreeClassifier().fit(x_train, y_train)
dt_pred = dt_model.predict(x_test)
print("Decision Tree Accuracy:", accuracy_score(y_test, dt_pred))

nb_model = GaussianNB().fit(x_train, y_train)
nb_pred = nb_model.predict(x_test)
print("Naïve Bayes Accuracy:", accuracy_score(y_test, nb_pred))

print("Confusion Matrix:\n", confusion_matrix(y_test, nb_pred))
print("Recall:", recall_score(y_test, nb_pred))
print("Precision:", precision_score(y_test, nb_pred))

plt.figure(figsize=(12, 12))
plot_tree(dt_model, filled=True, feature_names=col_names[:-1], class_names=["No", "Yes"], max_depth=3)
plt.show()



Bayes Classifier:
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix

# Load dataset
msg = pd.read_csv('comments.csv', names=['message', 'label'])
msg['labelnum'] = msg.label.map({'pos': 1, 'neg': 0})

# Split dataset
x_train, x_test, y_train, y_test = train_test_split(msg.message, msg.labelnum)

# Vectorization
vectorizer = CountVectorizer()
x_train_dtm, x_test_dtm = vectorizer.fit_transform(x_train), vectorizer.transform(x_test)

# Train and Predict
clf = MultinomialNB().fit(x_train_dtm, y_train)
predicted = clf.predict(x_test_dtm)

# Evaluation Metrics
print(f"Accuracy: {accuracy_score(y_test, predicted):.2f}")
print(f"Recall: {recall_score(y_test, predicted):.2f}")
print(f"Precision: {precision_score(y_test, predicted):.2f}")
print("Confusion Matrix:\n", confusion_matrix(y_test, predicted))














Prac8: Random Forest Regressor:
import pandas as pd
import warnings
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

warnings.filterwarnings('ignore')

df = pd.read_csv('roles.csv')

# Feature and target selection
X = df.iloc[:, 1:2].values
Y = df.iloc[:, 2].values

# Handling categorical variables
x_categorical = df.select_dtypes(include=['object']).apply(LabelEncoder().fit_transform)
x_numerical = df.select_dtypes(exclude=['object']).values
X = pd.concat([pd.DataFrame(x_numerical), x_categorical], axis=1).values

# Training the model
regressor = RandomForestRegressor(n_estimators=10, random_state=0, oob_score=True).fit(X, Y)

# Model evaluation
print(f'Out of Bag Score: {regressor.oob_score_}')
predictions = regressor.predict(X)
print(f'Mean Squared Error: {mean_squared_error(Y, predictions)}')
print(f'R2 Score: {r2_score(Y, predictions)}')

Prac7: Kmeans clustering
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

x = [4,5,10,4,3,11,14,6,10,12]
y = [21,19,24,17,16,25,24,22,21,21]

plt.scatter(x,y)
plt.show()

data=list(zip(x,y))
inertias=[]

for i in range(1,11):
    Kmeans=KMeans(n_clusters=i)
    Kmeans.fit(data)
    inertias.append(Kmeans.inertia_)

plt.plot(range(1,11),inertias,marker="o")
plt.title("Elbow Method")
plt.xlabel("Number of clusters")
plt.ylabel("Inertia")
plt.show()

Kmeans=KMeans(n_clusters=2)
Kmeans.fit(data)
plt.scatter(x,y,c=Kmeans.labels_)
plt.show()


Prac10:SVM
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score
from matplotlib.colors import ListedColormap

df = pd.read_csv('Salary_Data.csv')
X, y = df.iloc[:, [0, 1]].values, df.iloc[:, 2].values

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)

scaler = StandardScaler()
x_train, x_test = scaler.fit_transform(x_train), scaler.transform(x_test)

clf = SVC(kernel='poly', random_state=0).fit(x_train, y_train)

y_pred = clf.predict(x_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print(f'Model Accuracy: {accuracy_score(y_test, y_pred):.4f}')

x1, x2 = np.meshgrid(np.arange(x_train[:, 0].min() - 1, x_train[:, 0].max() + 1, 0.01),
                     np.arange(x_train[:, 1].min() - 1, x_train[:, 1].max() + 1, 0.01))

plt.contourf(x1, x2, clf.predict(np.c_[x1.ravel(), x2.ravel()]).reshape(x1.shape), alpha=0.75, cmap=ListedColormap(['red', 'green']))
plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, cmap=ListedColormap(['red', 'green']), edgecolors='k')
plt.title('SVM Classifier (Training set)')
plt.xlabel('Experience')
plt.ylabel('Salary')
plt.legend(['Class 0', 'Class 1'])
plt.show()



SVM: With Heatmap:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score

# Load dataset
df = pd.read_csv('Salary_Data.csv')
X = df.iloc[:, [0, 1]].values
y = df.iloc[:, 2].values

# Split dataset
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)

# Feature scaling
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

# Train SVM model
clf = SVC(kernel='poly', random_state=0)
clf.fit(x_train, y_train)

# Predictions
y_pred = clf.predict(x_test)

# Confusion Matrix Heatmap
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Model Accuracy
print(f'Model Accuracy: {accuracy_score(y_test, y_pred):.4f}')

Prac10:Heatmap
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix

data_set = pd.read_csv('pulsar_stars.csv')

X = data_set.iloc[:, [0, 1]].values
y = data_set.iloc[:, 2].astype(int).values  # Ensure categorical

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

classifier = SVC(kernel='linear', random_state=0)
classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)
cm = confusion_matrix(y_test, y_pred)
print('Accuracy Score:', accuracy_score(y_test, y_pred))

plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Heatmap')
plt.show()

